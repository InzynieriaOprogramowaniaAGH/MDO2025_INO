
# # Zajƒôcia 08) Sprawozdanie  z konfiguracji Ansible i zarzƒÖdzania 

## üì¶ 1. Instalacja zarzƒÖdcy Ansible

### üåµ Utworzenie drugiej maszyny wirtualnej
Utworzono maszynƒô `ansible-target` z minimalnym zestawem oprogramowania, co ograniczy≈Ço zbƒôdne us≈Çugi i poprawi≈Ço wydajno≈õƒá.

### üåµ Taki sam system operacyjny jak maszyna g≈Ç√≥wna
Obie maszyny dzia≈ÇajƒÖ na systemie Ubuntu 24.04 LTS, co u≈Çatwia zarzƒÖdzanie i eliminuje problemy kompatybilno≈õci.

### üåµ Instalacja `tar` i `sshd`
Zainstalowano `tar` i `openssh-server`, aby umo≈ºliwiƒá obs≈Çugƒô archiw√≥w i dostƒôp przez SSH.

### üåµ Nadanie hostname `ansible-target`
Nazwa hosta zosta≈Ça ustawiona ju≈º podczas instalacji systemu ale jeszcze siƒô upewni≈Çem.

![Opis](ss/1.jpg)


### üåµ Wykonanie migawki maszyny
Zrobiono migawkƒô w VirtualBoxie, co pozwala wr√≥ciƒá do stanu poczƒÖtkowego w razie problem√≥w.

![Opis](ss/20.png)

### üåµ Instalacja Ansible na g≈Ç√≥wnej maszynie
Na `server` zainstalowano Ansible za pomocƒÖ APT:
```bash
sudo apt update && sudo apt install -y ansible
```
![Opis](ss/21.png)



### üåµ Wymiana kluczy SSH
Na `server` wygenerowano parƒô kluczy SSH i przes≈Çano je do `ansible@ansible-target`:
```bash
ssh-keygen
ssh-copy-id ansible@ansible-target
```
![Opis](ss/6.png)

---

## üóÇÔ∏è 2. Inwentaryzacja

### üåµ Ustawienie nazw host√≥w
Ustawiono `hostnamectl` na obu maszynach:
```bash
hostnamectl set-hostname server
hostnamectl set-hostname ansible-target
```
![Opis](ss/7.png)



### üåµ Dodanie wpis√≥w do /etc/hosts
Na maszynie `server` wpisano:
```
192.168.100.10 ansible-target
192.168.100.11 server
```
![Opis](ss/22.png)



### üåµ Weryfikacja ≈ÇƒÖczno≈õci
Sprawdzono po≈ÇƒÖczenie:
```bash
ping ansible-target
ping server
```
![Opis](ss/23.png)



### üåµ Stworzenie pliku inwentaryzacji
Plik `inventory.ini`:
```ini
[Orchestrators]
server ansible_host=server ansible_user=krzysztof ansible_port=2222

[Endpoints]
ansible-target ansible_host=ansible-target ansible_user=ansible
```
![Opis](ss/6,5.png)
![Opis](ss/8.png)


### üåµ Wys≈Çanie ping przez Ansible
```bash
ansible -i inventory.ini all -m ping
```
![Opis](ss/11.png)




### üåµ U≈ºyto dw√≥ch maszyn wirtualnych
Projekt zosta≈Ç przeprowadzony z wykorzystaniem dw√≥ch maszyn: `server` i `ansible-target`.

### üåµ Ponowna wymiana kluczy ssh-copy-id
Upewniono siƒô, ≈ºe u≈ºytkownik `ansible` ma poprawnie dodany klucz publiczny.

### üåµ Weryfikacja bezhas≈Çowego logowania
SSH dzia≈Ça≈Ço bez potrzeby wpisywania has≈Ça.

![Opis](ss/6.png)
---

## ‚öôÔ∏è 3. Zdalne wywo≈Çywanie procedur

### üåµ Pingowanie z playbooka
Utworzono `ping.yml`:
```yaml
- hosts: all
  gather_facts: false
  tasks:
    - name: Ping
      ansible.builtin.ping:
```
![Opis](ss/12.png)

![Opis](ss/13.png)


### üåµ Skopiowanie pliku inwentaryzacji na zdalnƒÖ maszynƒô
```yaml
- hosts: Endpoints
  gather_facts: false
  tasks:
    - name: Copy inventory
      copy:
        src: ../inventory.ini
        dest: /home/ansible/inventory.ini
```

![Opis](ss/14.png)

![Opis](ss/15.png)

### üåµ Por√≥wnanie wynik√≥w
Po skopiowaniu inventory na `ansible-target` uruchomiono test pingowy zdalnie ‚Äî wynik by≈Ç identyczny jak z `server`.

### üåµ Aktualizacja systemu
```yaml
- hosts: Endpoints
  become: true
  tasks:
    - name: Update APT
      apt:
        update_cache: yes

    - name: Upgrade packages
      apt:
        upgrade: dist
```

![Opis](ss/16.png)
![Opis](ss/17.png)

### üåµ Restart us≈Çug sshd i rngd
```yaml
- hosts: Endpoints
  become: true
  tasks:
    - name: Restart sshd
      service:
        name: ssh
        state: restarted

    - name: Restart rngd
      service:
        name: rngd
        state: restarted
      ignore_errors: true
```

![Opis](ss/18.png)
![Opis](ss/19.png)

### üåµ Test awarii (SSH down, interfejs down)
Wy≈ÇƒÖczono `sshd` i kartƒô sieciowƒÖ. Ansible zg≈Çosi≈Ç `UNREACHABLE` ‚Äî zgodnie z oczekiwaniami.

![Opis](ss/a1.png)
![Opis](ss/a2.png)

---

## üê≥ 4.  ZarzƒÖdzanie stworzonym artefaktem

  

W ramach zadania przygotowano rolƒô Ansible s≈Çu≈ºƒÖcƒÖ do zarzƒÖdzania artefaktem. Rolƒô utworzono za pomocƒÖ komendy:

  

```

ansible-galaxy init manage_artifact

```

  

![Tworzenie roli Ansible](ss/p1.png)

  

Nastƒôpnie uruchomiono playbook `playbook.yml` wykorzystujƒÖcy utworzonƒÖ rolƒô:

  

```

ansible-playbook -i inventory playbook.yml

```

  

Efekt dzia≈Çania przedstawia poni≈ºszy zrzut ekranu:

  

![Wynik dzia≈Çania playbooka](ss/p2.png)

  

---

  

## Plik `playbook.yml`

  

Zawarto≈õƒá pliku `playbook.yml`, kt√≥ry definiuje u≈ºycie roli `manage_artifact`:

  

![playbook.yml](ss/p3.png)

  

---

  

## Zawarto≈õƒá pliku `main.yml` z roli `manage_artifact`

  

Plik zawiera nastƒôpujƒÖce kroki:

  

1. Instalacja Dockera

2. Weryfikacja dzia≈Çania Dockera

3. Przesy≈Çanie artefakt√≥w i Dockerfile

4. Budowanie obrazu Dockera

5. Uruchamianie kontenera z aplikacjƒÖ


  

Poni≈ºej przedstawiono zawarto≈õƒá pliku:


![main.yml czƒô≈õƒá 1](ss/p4.png)  

![main.yml czƒô≈õƒá 2](ss/p4.4.png)

_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________



# Zajƒôcia 09) Sprawozdanie: Pliki odpowiedzi dla wdro≈ºe≈Ñ nienadzorowanych

## üéØ Zagadnienie

Zadanie dotyczy≈Ço przygotowania automatycznego ≈∫r√≥d≈Ça instalacyjnego systemu Fedora 42 ‚Äî przydatnego w ≈õrodowiskach testowych, serwerowych lub IoT. Instalacja mia≈Ça odbywaƒá siƒô w pe≈Çni automatycznie, dziƒôki zastosowaniu pliku odpowiedzi Kickstart.

---

## üéØ Cel zadania

- Utworzenie pliku odpowiedzi `kickstart` do instalacji systemu.
- Zainstalowanie systemu Fedora 42 na maszynie wirtualnej w trybie nienadzorowanym.
- Upewnienie siƒô, ≈ºe system uruchamia siƒô w pe≈Çni skonfigurowany i gotowy do hostowania aplikacji.

---

## üì¶ ≈örodowisko i narzƒôdzia

- Oracle VirtualBox
- Obraz ISO Fedora 42 Everything Netinst
- Plik `anaconda-ks.cfg` z repozytorium GitHub
- Edytor nano, przeglƒÖdarka, TinyURL

---

## ü™ú Kroki realizacji

### 1. Uruchomienie instalatora z ISO

Na poczƒÖtku uruchomi≈Çem maszynƒô wirtualnƒÖ z obrazem instalacyjnym Fedora 42 w trybie ‚ÄúTest this media & install Fedora 42‚Äù.

üì∑ 
![Opis](ss/201.png)
![Opis](ss/202.png)



---

### 2. Problem z d≈Çugim linkiem i u≈ºycie TinyURL

Podczas konfiguracji GRUB okaza≈Ço siƒô, ≈ºe nie mogƒô wkleiƒá d≈Çugiego linku z GitHub Raw z plikiem Kickstart. W zwiƒÖzku z tym postanowi≈Çem u≈ºyƒá serwisu [TinyURL](https://tinyurl.com) do skr√≥cenia odno≈õnika.

```
#version=DEVEL
text
skipx
cdrom

keyboard --vckeymap=pl --xlayouts='pl'
lang pl_PL.UTF-8
timezone Europe/Warsaw --utc

rootpw --iscrypted --allow-ssh $y$j9T$u5Te1Uv/zc1G30Bm1z7ipamDc$3EBAqr78ouqUbIZt/CgcookAh0LiFJbyumYqU4WzW5
user --groups=wheel --name=user --password=haslohaslo --plaintext --iscrypted --gecos="user"

ignoredisk --only-use=sda
clearpart --all --initlabel
autopart

firstboot --enable

%packages
@^custom-environment
%end

reboot
```


![Opis](ss/203.png)
![Opis](ss/204.png)

Link do pliku Kickstart:
```
https://tinyurl.com/bdejyufr
```

---

### 3. Uruchomienie instalacji z pliku Kickstart

Instalator wykry≈Ç plik Kickstart i rozpoczƒÖ≈Ç instalacjƒô automatycznƒÖ. W logach widaƒá by≈Ço, ≈ºe u≈ºywany jest tryb tekstowy, co potwierdza wykorzystanie `inst.ks`.


![Opis](ss/206.png)
![Opis](ss/207.png)


---

### 4. Wej≈õcie do Anaconda GUI

Choƒá instalacja by≈Ça automatyczna, pojawi≈Ço siƒô okno z podsumowaniem konfiguracji. Musia≈Çem rƒôcznie potwierdziƒá konfiguracjƒô u≈ºytkownika i konta root.

![Anaconda GUI - podsumowanie instalacji](ss/209.png)

---

### 5. Postƒôp instalacji

Nastƒôpnie instalacja postƒôpowa≈Ça dalej, tworzƒÖc partycjƒô rozruchowƒÖ i systemowƒÖ.

![Anaconda GUI - podsumowanie instalacji](ss/212.png)

---____________________________________________________________________________________________________________________________________________________________________________________________________________________
____________________________________________________________________________________________________________________________________________________________________________________________________________________
____________________________________________________________________________________________________________________________________________________________________________________________________________________
____________________________________________________________________________________________________________________________________________________________________________________________________________________
____________________________________________________________________________________________________________________________________________________________________________________________________________________





# Zajƒôcia 10 ‚Äì Kubernetes (1)

## Wdra≈ºanie na zarzƒÖdzalne kontenery: Kubernetes

### Instalacja klastra Kubernetes

Na potrzeby zajƒôƒá zdecydowa≈Çem siƒô skorzystaƒá z `minikube`, czyli lekkiej implementacji Kubernetes do ≈õrodowisk lokalnych. Dziƒôki niej mogƒô przeprowadziƒá pe≈ÇnƒÖ konfiguracjƒô klastra, testy oraz wdro≈ºenia bez potrzeby korzystania z chmury.

#### Pobranie Minikube

Na poczƒÖtku pobra≈Çem najnowszƒÖ wersjƒô Minikube:
```
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
```

![Pobieranie Minikube](ss/z1.png)

#### Instalacja binarki

Nastƒôpnie zainstalowa≈Çem plik wykonywalny w katalogu `/usr/local/bin`:
```
sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

![Instalacja binarki](ss/z2.png)

#### Uruchomienie klastra

Uruchomi≈Çem Minikube z wykorzystaniem sterownika Docker oraz zadeklarowaniem zasob√≥w:
```
minikube start --driver=docker --cpus=2 --memory=2048
```

![Start klastra](ss/z3.png)

### Weryfikacja dzia≈Çania klastra

Sprawdzi≈Çem namespace'y oraz role:
```
minikube kubectl -- get namespaces
minikube kubectl -- get clusterrolebindings
```

![Namespaces](ss/z5.png)
![Cluster Roles](ss/z4.png)

Dla pewno≈õci zajrza≈Çem do certyfikat√≥w:
```
minikube ssh
ls /var/lib/minikube/certs/
```

![Certyfikaty](ss/z6.png)

---

## Dashboard Kubernetes

Dashboard uruchomi≈Çem za pomocƒÖ:
```
minikube dashboard
```

![Dashboard start](ss/z7.png)

Z poziomu przeglƒÖdarki uzyska≈Çem dostƒôp do interfejsu:
![Dashboard GUI](ss/z10.png)

---

## Uruchamianie aplikacji ‚Äì pojedynczy Pod

Postanowi≈Çem przetestowaƒá wdro≈ºenie kontenera z aplikacjƒÖ nginx:
```
minikube kubectl -- run moja-aplikacja --image=nginx --port=80 --labels app=moja-aplikacja
```



Sprawdzi≈Çem jego status:
```
minikube kubectl -- get pods
```
![Pod gotowy](ss/z8.png)


Nastƒôpnie przekierowa≈Çem port:
```
minikube kubectl -- port-forward pod/moja-aplikacja 8080:80
```

Z przeglƒÖdarki na moim Windowsie odwiedzi≈Çem `http://localhost:8080`:
![Port-forward dzia≈Ça](ss/z13.png)
![Port-forward dzia≈Ça](ss/z14.png)

Komunikacja dzia≈Ça poprawnie, strona Nginxa siƒô za≈Çadowa≈Ça.

---

## Tworzenie pliku YAML dla Deploymentu

Przekszta≈Çci≈Çem powy≈ºsze wdro≈ºenie w pe≈Çnoprawny `Deployment` i `Service`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  type: NodePort
  ports:
  - port: 80
    targetPort: 80
    nodePort: 30080
```

Plik zapisa≈Çem jako `nginx-deployment.yml`.

![Plik YAML](ss/z16.png)

Wdro≈ºenie wykona≈Çem komendƒÖ:
```
minikube kubectl -- apply -f nginx-deployment.yml
```

![Wdro≈ºenie](ss/z15.png)
![Wdro≈ºenie](ss/z16.png)
---

## Sprawdzanie rollout i dzia≈Çania aplikacji

Status rollout:
```
minikube kubectl -- rollout status deployment/nginx-deployment
```

![Rollout](ss/z17.png)

Sprawdzi≈Çem dzia≈ÇajƒÖce Pody:
```
minikube kubectl -- get pods
```

Sprawdzi≈Çem dostƒôpno≈õƒá serwisu:
```
minikube service nginx-service --url
```

![Pody i serwis](ss/z18.png)

Z przeglƒÖdarki odwiedzi≈Çem podany adres IP i port:
![Strona Nginx](ss/z14.png)

_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
_______________________________________________________________________________________________________________________________________________________





  

# Zajƒôcia 11

  

## Wdra≈ºanie na zarzƒÖdzalne kontenery: Kubernetes (2)

  

---

  

## Zadania do wykonania

  

### Przygotowanie nowego obrazu

  

Na poczƒÖtku stworzy≈Çem nowy katalog `my-nginx`, w kt√≥rym przygotowa≈Çem w≈Çasny Dockerfile. Doda≈Çem do kontenera niestandardowƒÖ stronƒô HTML, aby mieƒá pe≈ÇnƒÖ kontrolƒô nad jego zawarto≈õciƒÖ.

  

```bash

mkdir  my-nginx && cd  my-nginx

nano  Dockerfile

mkdir  my-custom-content

echo  "Hello, this is my custom Nginx page!" > my-custom-content/index.html

```

  

Zbudowa≈Çem pierwszy obraz i opublikowa≈Çem go w Docker Hub:

  

```bash

docker  build  -t  iogougou/my-nginx:v1  .

docker  login

docker  push  iogougou/my-nginx:v1

```

  

![Strona Nginx](ss/x1.png)

![Strona Nginx](ss/x2.png)

![Strona Nginx](ss/x3.png)

  

W kolejnych krokach przygotowa≈Çem wersje `v2` i `v3`, gdzie `v3` zawiera≈Ça b≈ÇƒôdnƒÖ konfiguracjƒô:

  

```bash

docker  build  -t  iogougou/my-nginx:v2  .

docker  push  iogougou/my-nginx:v2

  

echo "invalid_config" > my-custom-content/nginx.conf

docker build -t iogougou/my-nginx:v3 .

docker push iogougou/my-nginx:v3

```

  

![Strona Nginx](ss/x4.png)

![Strona Nginx](ss/x5.png)

  

---

  

### Zmiany w deploymencie

  

Przygotowa≈Çem plik `nginx-deployment.yaml` i wykona≈Çem deployment:

  

```bash

kubectl apply -f nginx-deployment.yaml

```

  

![Strona Nginx](ss/x6.png)

![Strona Nginx](ss/x7.png)

  

Sprawdzi≈Çem historiƒô rollout√≥w i wykona≈Çem rollback:

  

```bash

kubectl rollout history deployment/my-nginx-deployment

kubectl rollout undo deployment/my-nginx-deployment

```

  

![Strona Nginx](ss/x8.png)

![Strona Nginx](ss/x9.png)

![Strona Nginx](ss/x10.png)

  

---

  

## Kontynuacja dzia≈Ça≈Ñ

  

### Czƒôste aktualizacje deploymentu

  

Wielokrotnie edytowa≈Çem plik `nginx-deployment.yaml`, zmieniajƒÖc liczbƒô replik, wersjƒô obrazu itd.

  

![Strona Nginx](ss/x11.png)

  

---

  

### Weryfikacja wdro≈ºenia

  

Stworzy≈Çem skrypt `verify-deployment.sh`:

  

```bash

chmod +x verify-deployment.sh

./verify-deployment.sh

```

  

![Strona Nginx](ss/x12.png)

  

---

  

### Lista aktywnych pod√≥w

  

```bash

kubectl get pods -n default

```

  

![Strona Nginx](ss/x13.png)

  

---

  

## Strategie wdro≈ºenia

  

### Przygotowanie plik√≥w

  

```bash

nano Recreate.yaml

nano RollingUpdate.yaml

nano Canary.yaml

```

  


  

---

  

### Strategia 1: Recreate

  

![Strona Nginx](ss/x14.1.png)

  

---

  

### Strategia 2: Rolling Update

  

![Strona Nginx](ss/x14.2.png)

  

---

  

### Strategia 3: Canary Deployment

  ![Strona Nginx](ss/x14.3.png)



Zastosowa≈Çem dwa deploymenty, aby wdro≈ºyƒá wersjƒô canary.

  

---

  

### Wynik zastosowania strategii

  

```bash

kubectl apply -f Recreate.yaml

kubectl apply -f RollingUpdate.yaml

kubectl apply -f Canary.yaml

kubectl get deployments -n default

```

  

![Strona Nginx](ss/x16.png)



## üîÑ Por√≥wnanie strategii wdro≈ºeniowych

| Strategia         | G≈Ç√≥wne cechy                                                    | Przyk≈Çad z pod√≥w                      | Zalety                             | Wady                                |
|-------------------|------------------------------------------------------------------|----------------------------------------|------------------------------------|-------------------------------------|
| **Recreate**      | Usuwa wszystkie stare pody, dopiero potem uruchamia nowe.       | `my-nginx-recreate-*`                  | Prosta, brak konflikt√≥w wersji     | Kr√≥tka przerwa w dostƒôpno≈õci        |
| **RollingUpdate** | Stopniowo zamienia stare pody nowymi (czƒô≈õƒá dzia≈Ça r√≥wnolegle). | `my-nginx-rolling-update-*`            | Utrzymanie dostƒôpno≈õci             | Mo≈ºe trwaƒá d≈Çu≈ºej                   |
| **Canary**        | Nowa wersja uruchamiana tylko dla wybranych u≈ºytkownik√≥w.       | `my-nginx-canary-*`, `-replica-*`      | Minimalne ryzyko, kontrolowane     | Wymaga dodatkowej konfiguracji      |
