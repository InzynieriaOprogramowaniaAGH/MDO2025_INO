# **Sprawozdanie 3** - Metodyki DevOps
  kod:
  ```bash
  ```

- [x] **podpunkt**
  - **podpunkt**

_________________________________________________________________________________________________________________________________________________________
## **LAB 8 - Automatyzacja i zdalne wykonywanie poleceÅ„ za pomocÄ… Ansible** 

Celem Ä‡wiczeÅ„ byÅ‚o przygotowanie pliku odpowiedzi i wykorzystanie go do przeprowadzenia nienadzorowanej instalacji systemu Fedora. Podczas zajÄ™Ä‡ skonfigurowaÅ‚am instalator tak, aby system po uruchomieniu automatycznie zawieraÅ‚ wymagane repozytoria, zaleÅ¼noÅ›ci oraz uruchamiaÅ‚ moje oprogramowanie. DziÄ™ki temu udaÅ‚o siÄ™ w peÅ‚ni zautomatyzowaÄ‡ proces instalacji i wdroÅ¼enia Å›rodowiska testowego.

### Instalacja zarzÄ…dcy Ansible
- [x] **ğŸŒµ UtwÃ³rz drugÄ… maszynÄ™ wirtualnÄ… o **jak najmniejszym** zbiorze zainstalowanego oprogramowania**
  - **Zastosuj ten sam system operacyjny, co "gÅ‚Ã³wna" maszyna (najlepiej teÅ¼ w tej samej wersji)**
  - **Zapewnij obecnoÅ›Ä‡ programu `tar` i serwera OpenSSH (`sshd`)**

UÅ¼yÅ‚am poniÅ¼szych poleceÅ„ Å¼eby siÄ™ upeniÄ‡ Å¼e tar i sshd bÄ™dÄ… na maszynie:
```bash
sudo dnf install -y tar openssh-server
sudo systemctl enable sshd --now
```

  - **Nadaj maszynie *hostname* `ansible-target` (najlepiej jeszcze podczas instalacji)**

UstawiÅ‚am hostname poleceniem `sudo hostnamectl set-hostname ansible-target`. NastÄ™pnie zrestartowaÅ‚am system w celu wprowadzenia zmian dziÄ™ki `sudo reboot`

  - **UtwÃ³rz w systemie uÅ¼ytkownika `ansible` (najlepiej jeszcze podczas instalacji)**

StworzyÅ‚am uÅ¼ytkownika i stworzyÅ‚am do niego hasÅ‚o
``` bash
sudo useradd ansible
sudo passwd ansible
```
NadaÅ‚am mu teÅ¼ uprawnienia komendÄ… `sudo usermod -aG wheel ansible`.

  - **ZrÃ³b migawkÄ™ maszyny (i/lub przeprowadÅº jej eksport)**
W Hyper-V w odpowiednim miejscu w ustawieniach kliknÄ™Å‚am stworzeni migawki (punktu kontrolnego) maszyny. 
![image](https://github.com/user-attachments/assets/0a1ff97f-9f44-4d7d-a75e-d1f65f96a325)

ZaÅ› aby wykonaÄ‡ jej eksport musiaÅ‚abym tak jak poniÅ¼ej na wyÅ‚Ä…czonej maszynie kilkajÄ…c prawym przyciskiem na maszynÄ™ wybrac miejsce docelwoe jej eksportowania i mogÅ‚abym siÄ™ wÃ³wczas cieszyÄ‡ zapisem mojej maszyny:

![image](https://github.com/user-attachments/assets/f42364e0-512b-49f5-a73b-abf3c1d259a0)

- [x] **ğŸŒµ Na gÅ‚Ã³wnej maszynie wirtualnej, zainstaluj oprogramowanie Ansible**

Na maszynie "Fedora" pobraÅ‚am ansible `sudo dnf install ansible -y`

- [x] **WymieÅ„ klucze SSH miÄ™dzy uÅ¼ytkownikiem w gÅ‚Ã³wnej maszynie wirtualnej, a uÅ¼ytkownikiem `ansible` z nowej tak, by logowanie `ssh ansible@ansible-target` nie wymagaÅ‚o podania hasÅ‚a**

SkorzystaÅ‚am z polecenia  `ssh-copy-id ansible@ansible-target`, niestety coÅ› poszÅ‚o nie tak i poÅ‚czÄ…enie wymagaÅ‚o podania hasÅ‚a:

![image](https://github.com/user-attachments/assets/ad564db3-eca1-4644-a6a4-f7e7f3dd8bcb)

Jak widaÄ‡, miaÅ‚am maÅ‚y porblem z wymianÄ… kluczy. WystarczyÅ‚o jednak ruchomiÄ‡ proces `ssh-agent (eval "$(ssh-agent -s)")`, a nastÄ™pnie dodaÅ‚am do niego mÃ³j klucz prywatny (`ssh-add ~/.ssh/id_ed25519`). Agent SSH przechowuje klucz w pamiÄ™ci i automatycznie go udostÄ™pnia przy kaÅ¼dej prÃ³bie poÅ‚Ä…czenia, dziÄ™ki czemu polecenie
`ssh ansible@ansible-target` loguje siÄ™ od razu â€“ bez ponownego pytania o passphrase. Teraz wymiana kluczy miÄ™dzy maszynami przebiegÅ‚a poprawnie:

![image](https://github.com/user-attachments/assets/f5798d6d-f7dc-4047-9d3b-f4ff8a1cfc2a)

SprawdziÅ‚am szybko poÅ‚Ä…czenie, w tym celu w pliku */etc/ansible/hosts* dodaÅ‚am linijkÄ™ 
```bash
[targets]
ansible-target
```
Rezultaty:
![image](https://github.com/user-attachments/assets/1347efd4-0cb9-4ee0-af5d-777b62c4ce67)

### Inwentaryzacja
- [x] **ğŸŒµ Dokonaj inwentaryzacji systemÃ³w**
  - **Ustal przewidywalne nazwy komputerÃ³w (maszyn wirtualnych) stosujÄ…c `hostnamectl`, Unikaj `localhost`.**

Na maszynie gÅ‚Ã³wnej uruchomiÅ‚am `hostnamectl set-hostname ansible-orchestrator`, a dla maszyny docelowej pozostaÅ‚a nazwa *ansible-target*

![image](https://github.com/user-attachments/assets/b9fa36e8-5019-4a50-8452-477715e198a6)

  - **WprowadÅº nazwy DNS dla maszyn wirtualnych, stosujÄ…c `systemd-resolved` lub `resolv.conf` i `/etc/hosts`**

W pliku /etc/hosts dodaÅ‚am wpisy przypisujÄ…ce statyczne adresy IP do nazw maszyn wirtualnych. DziÄ™ki temu moÅ¼liwe jest odwoÅ‚ywanie siÄ™ do komputerÃ³w za pomocÄ… nazw (np. ansible-orchestrator, ansible-target), zamiast zapamiÄ™tywania adresÃ³w IP. 

![image](https://github.com/user-attachments/assets/9fca6e63-a822-42ab-b534-49a9fad4f84d)

  - **Zweryfikuj Å‚Ä…cznoÅ›Ä‡**

W tym celu poprostu wykonaÅ‚am *ping*:
![image](https://github.com/user-attachments/assets/1c0a4691-841c-48ca-a94c-f74276b3144d)


  - **StwÃ³rz plik inwentaryzacji]**
  - **UmieÅ›Ä‡ w nim sekcje `Orchestrators` oraz `Endpoints`. UmieÅ›Ä‡ nazwy maszyn wirtualnych w odpowiednich sekcjach**

UtowrzyÅ‚am plik hosts.ini (INI to format pliku konfiguracyjnego - nazwa od "initialization")
hosts.ini:
```
[Orchestrators]
ansible-orchestrator ansible_user=kaoina

[Endpoints]
ansible-target ansible_user=ansible

```

  - **ğŸŒµ WyÅ›lij Å¼Ä…danie `ping` do wszystkich maszyn**
Aby to zrobiÄ‡ wykonaÅ‚am polecenie `ansible all -i hosts.ini -m ping`. Polecenie to wykorzystuje Ansible do wysÅ‚ania Å¼Ä…dania ping do wszystkich hostÃ³w (all) zdefiniowanych w pliku hosts.ini. DziÄ™ki temu mogÅ‚am upewniÄ‡ siÄ™, Å¼e maszyny sÄ… dostÄ™pne przez SSH, poprawnie rozpoznajÄ… siÄ™ po nazwach
![image](https://github.com/user-attachments/assets/ad665af3-a1dc-49a5-8f1f-faf7a26dbf70)

- [x] **Zapewnij Å‚Ä…cznoÅ›Ä‡ miÄ™dzy maszynami**
  - **UÅ¼yj co najmniej dwÃ³ch maszyn wirtualnych**
  - **Dokonaj wymiany kluczy miÄ™dzy maszynÄ…-dyrygentem, a koÅ„cÃ³wkami**

Aby zapewniÄ‡ bezhasÅ‚owÄ… Å‚Ä…cznoÅ›Ä‡ SSH miÄ™dzy maszynÄ…-dyrygentem (ansible-orchestrator) a maszynami docelowymi (ansible-target oraz samym orchestrator), wygenerowaÅ‚am parÄ™ kluczy SSH (jeÅ›li jeszcze nie istniaÅ‚a), a nastÄ™pnie przesÅ‚aÅ‚am klucz publiczny na maszyny docelowe przy uÅ¼yciu polecenia ssh-copy-id. OperacjÄ™ wykonaÅ‚am dla obu maszyn:
```bash
ssh-copy-id kaoina@ansible-orchestrator 
ssh-copy-id ansible@ansible-target
```
  - **Upewnij siÄ™, Å¼e Å‚Ä…cznoÅ›Ä‡ SSH miÄ™dzy maszynami jest moÅ¼liwa i nie potrzebuje haseÅ‚**
Aby upewniÄ‡ siÄ™, Å¼e Å‚Ä…cznoÅ›Ä‡ SSH miÄ™dzy maszynami nie wymaga podawania hasÅ‚a, uruchomiÅ‚am agenta SSH poleceniem `eval "$(ssh-agent -s)"`. NastÄ™pnie dodaÅ‚am klucz prywatny do agenta za pomocÄ… `ssh-add ~/.ssh/id_ed25519`. Po podaniu hasÅ‚a do klucza klucz zostaÅ‚ zaÅ‚adowany i mogÅ‚am poÅ‚Ä…czyÄ‡ siÄ™ z maszynÄ… ansible-target poleceniem ssh ansible@ansible-target bez potrzeby podawania hasÅ‚a do uÅ¼ytkownika.

![image](https://github.com/user-attachments/assets/8096a149-55b3-4263-bd8a-c6cd1e97d930)

### Zdalne wywoÅ‚ywanie procedur
Za pomocÄ… playbooka Ansible:
  - [x] **ğŸŒµ WyÅ›lij Å¼Ä…danie `ping` do wszystkich maszyn**
  - [x] **Skopiuj plik inwentaryzacji na maszyny/Ä™ `Endpoints`**
  - [x] **PonÃ³w operacjÄ™, porÃ³wnaj rÃ³Å¼nice w wyjÅ›ciu**

ZawartoÅ›Ä‡ playbooka:
```bash
- name: Ping and copy inventory file
  hosts: all
  tasks:
    - name: Ping each host
      ansible.builtin.ping:

    - name: Copy hosts.ini to endpoints
      copy:
        src: ./hosts.ini
        dest: /tmp/hosts.ini
      when: "'ansible-target' in inventory_hostname"
```
WywoÅ‚anie playbooka komendÄ…: ` ansible-playbook -i hosts.ini ping_and_copy.yml `
NastÄ™pnie poÅ‚Ä…czyÅ‚am siÄ™ zdalnie z ansible-target, aby upewniÄ‡ siÄ™, Å¼e plik zostaÅ‚ poprawnie skopiowany do */tmp/hosts.ini*:
![image](https://github.com/user-attachments/assets/bf58eee1-abd2-4d70-b84d-8a888ca375c3)

Pierwsze uruchomienie:
![image](https://github.com/user-attachments/assets/78e005c4-331e-40ab-81c1-4e0fbff07084)

Kolejne uruchomienie:
![image](https://github.com/user-attachments/assets/b162ff46-49c5-4507-a687-2d97534202e5)

Przy kolejnym uruchomieniu:
-	ping dalej dziaÅ‚a
-	copy pokazuje ok zamiast changed
Przy ponownym uruchomieniu playbooka, zadanie ping nadal potwierdza Å‚Ä…cznoÅ›Ä‡ ze wszystkimi maszynami, natomiast zadanie kopiowania pliku zwraca ok zamiast changed, poniewaÅ¼ zawartoÅ›Ä‡ pliku hosts.ini na maszynie docelowej nie ulegÅ‚a zmianie. To pokazuje, Å¼e Ansible nie wykonuje zmian, jeÅ›li nie sÄ… potrzebne.

  - [x] **Zaktualizuj pakiety w systemie**

Aby zaktualizowaÄ‡ wszystkie pakiety na maszynach docelowych, przygotowaÅ‚am prosty playbook Ansible o nazwie update.yml. Playbook ten wykorzystuje moduÅ‚ dnf do bezpiecznej aktualizacji wszystkich pakietÃ³w do najnowszych wersji:
```bash
- name: Update all packages on Endpoints
  hosts: Endpoints
  become: true
  tasks:
    - name: Update all packages (safe way)
      ansible.builtin.dnf:
        name: "*"
        state: latest
        update_cache: yes
```
Playbook uruchomiÅ‚am komendÄ… ` ansible-playbook -i hosts.ini update.yml --ask-become-pass`. Ze wzglÄ™du na to, Å¼e aktualizacja pakietÃ³w wymaga uprawnieÅ„ administratora, musiaÅ‚am dodaÄ‡ opcjÄ™ --ask-become-pass, aby Ansible zapytaÅ‚o o hasÅ‚o do sudo.

![image](https://github.com/user-attachments/assets/c7748060-6cd8-4f54-a0dd-4580c4b13371)

  - [x] **Zrestartuj usÅ‚ugi `sshd` i `rngd`**

Aby zrealizowaÄ‡ zadanie polegajÄ…ce na restarcie usÅ‚ug sshd i rngd na maszynach koÅ„cowych, przygotowaÅ‚am playbook restart.yml, ktÃ³ry wyglÄ…daÅ‚ nastÄ™pujÄ…co:
plik *restart.yml*:
```bash
- name: Restart sshd and rngd services on Endpoints
  hosts: Endpoints
  become: true
  tasks:
    - name: Restart sshd
      ansible.builtin.service:
        name: sshd
        state: restarted

    - name: Restart rngd
      ansible.builtin.service:
        name: rngd
        state: restarted
```

PoczÄ…tkowo uruchomienie playbooka zakoÅ„czyÅ‚o siÄ™ bÅ‚Ä™dem
![image](https://github.com/user-attachments/assets/3a923204-5d2d-44da-89ef-58e68c370200)

UsÅ‚uga rngd nie byÅ‚a dostÄ™pna na systemie ("Could not find the requested service rngd"). SprawdziÅ‚am jej status (`systemctl status rngd`), a nastÄ™pnie zainstalowaÅ‚am brakujÄ…cy pakiet `sudo dnf install rng-tools`

![image](https://github.com/user-attachments/assets/db742689-6452-4ea0-ba85-779cfedbdc6d)

Ponowne wykonanie playbooka zakoÅ„czyÅ‚o siÄ™ peÅ‚nym sukcesem. DziÄ™ki temu oba demony (sshd i rngd) zostaÅ‚y zrestartowane automatycznie z poziomu Ansible.
![image](https://github.com/user-attachments/assets/e8c31f7c-ebab-4335-9741-af94d5f00faf)

  - [x] **PrzeprowadÅº operacje wzglÄ™dem maszyny z wyÅ‚Ä…czonym serwerem SSH, odpiÄ™tÄ… kartÄ… sieciowÄ…**
Po odÅ‚Ä…czeniu ssh na maszynie ansible (` sudo systemctl stop sshd`) otrzymaliÅ›my poniÅ¼szy wynik:

![image](https://github.com/user-attachments/assets/4a59f249-c842-4fe4-ac15-ccb7cc9533c0)

### ZarzÄ…dzanie stworzonym artefaktem
Za pomocÄ… playbooka Ansible:

- [x] **JeÅ¼eli artefaktem z Twojego *pipeline'u* byÅ‚ kontener:
  - **Zbuduj i uruchom kontener sekcji `Deploy` z poprzednich zajÄ™Ä‡**
  - **Pobierz z Docker Hub aplikacjÄ™ "opublikowanÄ…" w ramach kroku `Publish`**
  - **Na maszynie docelowej, **Dockera zainstaluj Ansiblem!**
  - **Zweryfikuj Å‚Ä…cznoÅ›Ä‡ z kontenerem**
  - **Zatrzymaj i usuÅ„ kontener**

W ramach zadania stworzyÅ‚am playbook do zarzÄ…dzania kontenerem Docker, ktÃ³ry jest efektem dziaÅ‚ania pipeline'u. CaÅ‚oÅ›Ä‡ zostaÅ‚a zaimplementowana w postaci roli Ansible. UtworzyÅ‚am strukturÄ™ roli przy pomocy komendy ` ansible-galaxy init docker_artifact`

![image](https://github.com/user-attachments/assets/c56cb3b6-159c-4aa0-b4a9-86e537405131)

W pliku docker_artifact/tasks/main.yml umieÅ›ciÅ‚am zadania odpowiedzialne za:
  * instalacjÄ™ i uruchomienie Dockera
  * pobranie kontenera kaoina666/redis_runtime:2 z Docker Hub
  * jego uruchomienie z odpowiednim przekierowaniem portu
  * sprawdzenie dostÄ™pnoÅ›ci usÅ‚ugi Redis
  * a nastÄ™pnie jego zatrzymanie i usuniÄ™cie

```bash
- name: Install Docker
  ansible.builtin.dnf:
    name: docker
    state: present
  become: true

- name: Enable and start Docker
  ansible.builtin.service:
    name: docker
    state: started
    enabled: true
  become: true

- name: Pull Redis image from Docker Hub
  community.docker.docker_image:
    name: kaoina666/redis_runtime
    tag: "2"
    source: pull

- name: Run Redis container
  community.docker.docker_container:
    name: redis_test
    image: kaoina666/redis_runtime:2
    state: started
    restart_policy: always
    published_ports:
      - "6380:6379"

- name: Wait for Redis to respond on port 6380
  ansible.builtin.wait_for:
    host: "127.0.0.1"
    port: 6380
    timeout: 15

- name: Stop Redis container
  community.docker.docker_container:
    name: redis_test
    state: stopped

- name: Remove Redis container
  community.docker.docker_container:
    name: redis_test
    state: absent
```
Aby dziaÅ‚aÅ‚o, muszÄ… byÄ‡ zainstalowane wszystkie potrzebne kolekcje:
![image](https://github.com/user-attachments/assets/2dfacd4a-2637-48e1-99d3-68bab6b054b4)

Plik requirements.yml:
```bash
collections:
  - name: community.docker
```
CaÅ‚oÅ›Ä‡ uruchomiÅ‚am przez playbook run_artifact.yml komendÄ… ` ansible-playbook -i hosts.ini run_artifact.yml --ask-become-pass`

![image](https://github.com/user-attachments/assets/d2c868f8-b548-40d9-b078-ca5252966640)

Moje run artifact:
```
- name: Manage Redis container artifact
  hosts: Endpoints
  become: true

  roles:
    - docker_artifact
```
Po uruchomieniu playbook wykonaÅ‚ wszystkie zadania poprawnie: Redis zostaÅ‚ pobrany i uruchomiony, a nastÄ™pnie zatrzymany i usuniÄ™ty.
_______________________________________________________________________
## **LAB 9 Pliki odpowiedzi dla wdroÅ¼eÅ„ nienadzorowanych (Kickstart)** 

Cel - 

### Zadanie
- [x] **podpunkt**
  - **podpunkt**
_________________________________________________________________
## **LAB 10 WdraÅ¼anie na zarzÄ…dzalne kontenery: Kubernetes (1)**

Cel - 

### Zadanie
- [x] **podpunkt**
  - **podpunkt**
_________________________________________________________________
## **LAB 11 WdraÅ¼anie na zarzÄ…dzalne kontenery: Kubernetes (2)**

Cel - 

### Zadanie
- [x] **podpunkt**
  - **podpunkt**
