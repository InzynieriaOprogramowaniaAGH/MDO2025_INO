Marcin Ziemba 15.06.2025  
Sprawozdanie 3

Zacząłem od utworzenia 2 maszyny z Fedora Server, zmieniłem nazwę na **ansible-target,** pobrałem na niej tar i sshd, na głównej maszynie ansible.  
\`\`\`  
sudo dnf install ansible \-y  
\`\`\`  
Kolejno wymieniłem klucze między obiema maszynami:  
\`\`\`  
ssh-copy-id ansible@172.19.56.139  
\`\`\`

Po wymianie kluczy można wykonywać polecenia zdalnie bez podawania hasła:

\!\[\](../Sprawozdanie3/ss/lab8/ss1.png)

Inwentaryzacja

Zmieniłem nazwę maszyny host na fedora-server przy pomocy komendy:  
\`\`\`  
sudo hostnamectl set-hostname fedora-server  
\`\`\`

Kolejno zmieniłem plik inventory.ini i wysłałem ping:

\!\[\](../Sprawozdanie3/ss/lab8/ss2.png)  
\!\[\](../Sprawozdanie3/ss/lab8/ss3.png)

Zarządzanie stworzonym artefaktem

Treść playbook’a:

\`\`\`  
\- name: Tasks  
  hosts: Endpoints  
  become: yes  
  tasks:  
    \- name: Ping machines  
      ansible.builtin.ping:

    \- name: Copy inventory file  
      ansible.builtin.copy:  
        src: ./inventory.ini  
        dest: \~/inventory.ini

    \- name: Update packages  
      ansible.builtin.dnf:  
        name: '\*'  
        state: latest  
        update\_cache: yes

    \- name: Restart sshd and rngd  
      ansible.builtin.systemd:  
        name: "{{item}}"  
        state: restarted  
      loop:  
        \- sshd  
        \- rngd  
\`\`\`

Przy pierwszym uruchomieniu był problem z brakiem rng-tools na maszynie zdalnej, po instalacji rng-tools:

\!\[\](../Sprawozdanie3/ss/lab8/ss4.png)  
2 uruchomienie  
\!\[\](../Sprawozdanie3/ss/lab8/ss5.png)

Instalacje nienadzorowane

Stworzyłem nową instancję Fedora-Server bez użycia pliku odpowiedzi i pobrałem anaconda-ks.cfg:

Po pobraniu, zmodyfikowałem i przeniosłem plik anaconda-ks.cfg na swojego brancha: 

\`\`\`  
\# Generated by Anaconda 41.35  
\# Generated by pykickstart v3.58  
\#version=DEVEL

\# Keyboard layouts  
keyboard \--vckeymap=pl \--xlayouts='pl'

\# System language  
lang pl\_PL.UTF-8

\# Set hostname  
network \--hostname=fedora-pipeline.local

\# Packages  
%packages  
@^server-product-environment  
%end

\# Run the Setup Agent on first boot  
firstboot \--enable

\# Generated using Blivet version 3.11.0  
ignoredisk \--only-use=sda  
autopart  
\# Partition clearing information  
clearpart \--none \--initlabel

\# System timezone  
timezone Europe/Warsaw \--utc

\# Root password  
rootpw \--iscrypted $y$j9T$Xg.jlKkzuCIoJmbIDNfISszt$yRApWdsU7TyOuYstiAwHtzb67pq4cxABBS5/DwzW8  
\`\`\`

Następnie przy uruchamianiu nowo stworzonej maszyny przy opcji fedora kliknąłem e i dodałem następującą linię kodu:

\`\`\`  
inst.ks=https://raw.githubusercontent.com/InzynieriaOprogramowaniaAGH/MDO2025\_INO/refs/heads/MZ417749/ITE/GCL06/MZ417749/Sprawozdanie3/anaconda-ks.cfg  
\`\`\`

\!\[\](../Sprawozdanie3/ss/lab9/ss2.png)

Następnie po wciśnięciu f10 system automatycznie się zainstalował:

\!\[\](../Sprawozdanie3/ss/lab9/ss3.png)  
\!\[\](../Sprawozdanie3/ss/lab9/ss1.png)

Kubernetes

Zacząłem od zainstalowania **minikube’a** oraz **kubectl**

\!\[\](../Sprawozdanie3/ss/lab10/ss1.png)  
\!\[\](../Sprawozdanie3/ss/lab10/ss2.png)

Następnie uruchomiłem dashboard kommendą:

\`\`\`  
minikube dashboard  
\`\`\`

\!\[\](../Sprawozdanie3/ss/lab10/ss3.png)

Kolejno stworzyłem pierwszego poda:

\!\[\](../Sprawozdanie3/ss/lab10/ss4.png)  
\!\[\](../Sprawozdanie3/ss/lab10/ss5.png)

Następnie stworzyłem plik yaml zawierający wdrożenie i tworzący 4 repliki kontenera  
\`\`\`  
apiVersion: apps/v1  
kind: Deployment  
metadata:  
  name: nginx-deployment  
  labels:  
    app: nginx  
spec:  
  selector:  
    matchLabels:  
      app: nginx  
  template:  
    metadata:  
      labels:  
        app: nginx  
    spec:  
      containers:  
        \- name: nginx  
          image: nginx  
          ports:  
            \- containerPort: 80  
\`\`\`

Następnie dodałem 4 repliki:

\`\`\`  
kubectl apply \-f nginx-deployment.yaml  
kubectl get deployments  
kubectl get pods  
\`\`\`  
\!\[\](../Sprawozdanie3/ss/lab10/ss6.png)  
\!\[\](../Sprawozdanie3/ss/lab10/ss7.png)

Kolejne było skalowanie liczby replik:

\`\`\`  
kubectl scale deployment nginx-deployment \--replicas=8  
kubectl scale deployment nginx-deployment \--replicas=1  
kubectl scale deployment nginx-deployment \--replicas=0  
kubectl scale deployment nginx-deployment \--replicas=4  
\`\`\`

\!\[\](../Sprawozdanie3/ss/lab10/ss8.png)

Następnie w błędnej wersji obrazu i rollbacku zmieniłem image w nginx-deployment.yaml na nieistniejący:

\`\`\`  
kubectl apply \-f nginx-deployment.yaml  
kubectl get pods  
\`\`\`

\`\`\`  
kubectl rollout undo deployment nginx-deployment  
\`\`\`  
\!\[\](../Sprawozdanie3/ss/lab10/ss9.png)  
