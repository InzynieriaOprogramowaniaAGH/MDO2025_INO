# Sprawozdanie 3

---

## Laboratorium 8: Automatyzacja i zdalne wykonywanie poleceÅ„ za pomocÄ… Ansible

---
 
### Instalacja zarzÄ…dcy Ansible
* ğŸŒµ UtwÃ³rz drugÄ… maszynÄ™ wirtualnÄ… o **jak najmniejszym** zbiorze zainstalowanego oprogramowania
  * Zastosuj ten sam system operacyjny, co "gÅ‚Ã³wna" maszyna (najlepiej teÅ¼ w tej samej wersji)

    WykorzystaÅ‚em ten sam obraz do instalacji tego systemu co do instalacji gÅ‚Ã³wnej maszyny

  * Zapewnij obecnoÅ›Ä‡ programu `tar` i serwera OpenSSH (`sshd`)

    Sshd zostaÅ‚ zainstalowany automatycznie po wybraniu instalacji Server Edition, a tar zainstalowaÅ‚em poleceniem: `dnf install tar`

  * Nadaj maszynie *hostname* `ansible-target` (najlepiej jeszcze podczas instalacji)

    NadaÅ‚em maszynie nazwÄ™: ansible-target

    ![Nadanie hostname podczas instalacji](Images/hostname.png "Nadanie hostname podczas instalacji")

  * UtwÃ³rz w systemie uÅ¼ytkownika `ansible` (najlepiej jeszcze podczas instalacji)

    Podczas instalacji stworzyÅ‚em uÅ¼ytkownika o nazwie ansible.

    ![Stworznie nowego uÅ¼ytkownika podczas instalacji](Images/new_user.png "Stworzenie nowego uÅ¼ytkownika")

  * ZrÃ³b migawkÄ™ maszyny (i/lub przeprowadÅº jej eksport)

    W virtual boxie, klikajÄ…c prawym przyciskiem na wirtulnej maszynie i wybierajÄ…c opcjÄ™: "Eksportuj do OCI..." moÅ¼na wyeksportowaÄ‡ maszynÄ™ do formatu .ovi

    ![Wyeksportowana maszyna virtualboxa](Images/eksport.png "Wyeksportowana maszyna virtualboxa")

* ğŸŒµ Na gÅ‚Ã³wnej maszynie wirtualnej (nie na tej nowej!), zainstaluj [oprogramowanie Ansible](https://docs.ansible.com/ansible/latest/installation_guide/index.html), najlepiej z repozytorium dystrybucji

    Ansible zainstalowaÅ‚em na gÅ‚Ã³wnej maszynie poleceniem: `dnf install ansible`

    ![Wyswietlenie wersji programu ansible, po instalacji](Images/installed_ansible.png "Zainstalowany Ansible")

* WymieÅ„ klucze SSH miÄ™dzy uÅ¼ytkownikiem w gÅ‚Ã³wnej maszynie wirtualnej, a uÅ¼ytkownikiem `ansible` z nowej tak, by logowanie `ssh ansible@ansible-target` nie wymagaÅ‚o podania hasÅ‚a
  
    Najpierw w celu rozpoznawania nazwy hostname dodaÅ‚em odpowiednie wpisy do pliku etc/hosts na gÅ‚Ã³wnej maszynie:

    ![etc/hosts](Images/etc_hosts.png "Wpis w etc/hosts")

    DziÄ™ki temu mogÅ‚em Å‚atwo wygenerowaÄ‡ i wymieniÄ‡ klucze, a nastÄ™pnie widaÄ‡ Å¼e byÅ‚em w stanie zalogowaÄ‡ siÄ™ przez ssh bez hasÅ‚a

    ![Wymiana kluczy i logowanie przez ssh bez klucza](Images/keys_exchange.png "Wymiana kluczy i logowanie przez ssh bez klucza")

### Inwentaryzacja
* ğŸŒµ Dokonaj inwentaryzacji systemÃ³w
  * Ustal przewidywalne nazwy komputerÃ³w (maszyn wirtualnych) stosujÄ…c `hostnamectl`, Unikaj `localhost`.

    Za pomocÄ… polecenia hostnamectl, zmieniÅ‚em hostname trzeciej maszyny ( sklonowana druga maszyna, PPM-> Klonuj w virtual boxie )

    ![Ustawianie hostname z wiersza poleceÅ„](Images/hostnamectl.png "Ustawianie hostname z wiersza poleceÅ„")

  * WprowadÅº nazwy DNS dla maszyn wirtualnych, stosujÄ…c `systemd-resolved` lub `resolv.conf` i `/etc/hosts` - tak, aby moÅ¼liwe byÅ‚o wywoÅ‚ywanie komputerÃ³w za pomocÄ… nazw, a nie tylko adresÃ³w IP

    DodaÅ‚em odpowiednie wpisy do etc/hosts:

    ![etc/hosts](Images/etc_hosts.png "Wpis w etc/hosts")

  * Zweryfikuj Å‚Ä…cznoÅ›Ä‡

    Po wykonaniu wszystkich powyÅ¼szych czynnoÅ›ci jestem w stanie, pingowaÄ‡ maszyny uÅ¼ywajÄ…c tylko ich hostname'y

    ![Pingowanie maszyn](Images/connectivity.png "Pingowanie maszyn")

  * StwÃ³rz [plik inwentaryzacji](https://docs.ansible.com/ansible/latest/getting_started/get_started_inventory.html)
  * UmieÅ›Ä‡ w nim sekcje `Orchestrators` oraz `Endpoints`. UmieÅ›Ä‡ nazwy maszyn wirtualnych w odpowiednich sekcjach

    StworzyÅ‚em odpowiedni plik inwentaryzacji, wpisujÄ…c same hostname'y

    ![Stworzony plik inwentaryzacji](Images/inventory_file.png "Plik inwentaryzacji")

  * ğŸŒµ WyÅ›lij Å¼Ä…danie `ping` do wszystkich maszyn

    Tym razem wykonaÅ‚em pingowanie, korzystajÄ…c z Ansible, pingujÄ…c caÅ‚Ä… sekcjÄ™ jednym poleceniem:

    ![Pingowanie z Ansible](Images/ansible_ping.png "Pingowanie z Ansible")   

* Zapewnij Å‚Ä…cznoÅ›Ä‡ miÄ™dzy maszynami
  * UÅ¼yj co najmniej dwÃ³ch maszyn wirtualnych (optymalnie: trzech)

    ZainstalowanÄ… maszynÄ™ sklonowaÅ‚em w virtual boxie, nastÄ™pnie musiaÅ‚em tylko na sklonowanej maszynie zmieniÄ‡ hostname, oraz upewniÄ‡ siÄ™ Å¼e adresy sieciowe zostaÅ‚y przydzielone inne niÅ¼ klonowana maszyna.

  * Dokonaj wymiany kluczy miÄ™dzy maszynÄ…-dyrygentem, a koÅ„cÃ³wkami (`ssh-copy-id`)

    Przeprowadzone tak jak wyÅ¼ej
  
  * Upewnij siÄ™, Å¼e Å‚Ä…cznoÅ›Ä‡ SSH miÄ™dzy maszynami jest moÅ¼liwa i nie potrzebuje haseÅ‚

    Nie potrzeba haseÅ‚, tak jak widaÄ‡ na jednym ze screenÃ³w.
  
### Zdalne wywoÅ‚ywanie procedur
Za pomocÄ… [*playbooka*](https://docs.ansible.com/ansible/latest/getting_started/get_started_playbook.html) Ansible:
  * WyÅ›lij Å¼Ä…danie `ping` do wszystkich maszyn
  * Skopiuj plik inwentaryzacji na maszyny/Ä™ `Endpoints`
  * PonÃ³w operacjÄ™, porÃ³wnaj rÃ³Å¼nice w wyjÅ›ciu
  * Zaktualizuj pakiety w systemie
  * Zrestartuj usÅ‚ugi `sshd` i `rngd`

    TreÅ›Ä‡ playbooka wykonujÄ…cego te operacje:

```yaml
    - name: My first play
  hosts: Endpoints
  tasks:
   - name: Pinguj maszyny
     ansible.builtin.ping:

   - name: Skopiuj plik  inwentaryzacji na maszyny
     ansible.builtin.copy:
        src: inventory.ini
        dest: /home/ansible/inventory.ini
        owner: ansible
        group: ansible
        mode: '0644'

   - name: Ponownie skopiuj plik inwentaryzacji na maszyny
     ansible.builtin.copy:
        src: inventory.ini
        dest: /home/ansible/inventory.ini
        owner: ansible
        group: ansible
        mode: '0644'

   - name: Zaktualizuj wszystkie pakiety w systemie
     ansible.builtin.package:
        name: "*"
        state: latest

   - name: Zrestartuj usÅ‚ugÄ™ sshd
     ansible.builtin.service:
        name: sshd
        state: restarted

   - name: Zrestartuj usÅ‚ugÄ™ rngd
     ansible.builtin.service:
        name: rngd
        state: restarted
```

    A efektem jego uruchomienia jest:

![Uruchomiony Playbook](Images/run_playbook.png "Efekt uruchomienia Playbooka")

Po pierwszym skopiowaniu pliku inwentaryzacji na maszyny status zadania to 'changed', poniewaÅ¼ w efekcie maszyny zmieniaÅ‚y swÃ³j stan.
Podczas drugiej prÃ³by kopiowania, status to 'ok' poniewaÅ¼ tym razem nie nastÄ…piÅ‚a Å¼adna zmiana na maszynie, poniewaÅ¼ ten plik juÅ¼ istniaÅ‚ w docelowej lokalizacji.

  * PrzeprowadÅº operacje wzglÄ™dem maszyny z wyÅ‚Ä…czonym serwerem SSH, odpiÄ™tÄ… kartÄ… sieciowÄ…

    Na jednej z maszyn wyÅ‚Ä…czyÅ‚em sshd, w efekcie playbook nie mÃ³gÅ‚ siÄ™ z tÄ… maszynÄ… poÅ‚Ä…czyÄ‡:

    ![Efekt wykonania playbooka gdy do jednej z maszyn nie ma dostÄ™pu](Images/run_playbook.png "Efekt wykonania playbooka gdy do jednej z maszyn nie ma dostÄ™pu")
  
### ZarzÄ…dzanie stworzonym artefaktem
Za pomocÄ… [*playbooka*](https://docs.ansible.com/ansible/latest/getting_started/get_started_playbook.html) Ansible:

* JeÅ¼eli artefaktem z Twojego *pipeline'u* byÅ‚ kontener:
  * Zbuduj i uruchom kontener sekcji `Deploy` z poprzednich zajÄ™Ä‡
  * Pobierz z Docker Hub aplikacjÄ™ "opublikowanÄ…" w ramach kroku `Publish`
  * Na maszynie docelowej, **Dockera zainstaluj Ansiblem!**
  * Zweryfikuj Å‚Ä…cznoÅ›Ä‡ z kontenerem
  * Zatrzymaj i usuÅ„ kontener

* JeÅ¼eli artefaktem z Twojego *pipeline'u* byÅ‚ plik binarny (lub ich zestaw):
  * WyÅ›lij plik aplikacji na zdalnÄ… maszynÄ™
  * StwÃ³rz kontener przeznaczony do uruchomienia aplikacji (zaopatrzony w zaleÅ¼noÅ›ci)
  * UmieÅ›Ä‡/udostÄ™pnij plik w kontenerze, uruchom w nim aplikacjÄ™
  * Zweryfikuj poprawne uruchomienie (a nie tylko wykonanie *playbooka*)
    
  TreÅ›Ä‡ tego playbooka:

```Yaml
- name: My second play
  hosts: Endpoints
  vars:
    remote_binary_path: /usr/bin/irssi
    container_name: irssiDep
    docker_image: fedora:latest 
  tasks:
   - name: Instalacja Dockera
     ansible.builtin.package:
        name: docker
        state: present

   - name: Start Dockera
     ansible.builtin.service:
        name: docker
        state: started
        enabled: true

   - name: Skopiowanie Binarki na maszyny
     ansible.builtin.copy:
        src: ./irssi
        dest: "{{ remote_binary_path }}"
        mode: '0755'
    
   - name: Stworzenie kontenera
     community.docker.docker_container:
        name: "{{ container_name }}"
        image: "{{ docker_image }}"
        state: started
        tty: true
        interactive: true
        command: "./irssi"
        volumes:
          - "{{ remote_binary_path }}:/irssi"
        restart_policy: unless-stopped

   - name: Pobranie listy procesÃ³w w dockerze ( w poszukiwaniu irssi )
     community.docker.docker_container_exec:
       container: "{{ container_name }}"
       command: "sh -c 'ls -l /proc/*/exe 2>/dev/null || true'"
     register: container_processes

   - name: Wypisanie procesÃ³w w dockerze ( w poszukiwaniu irssi )
     debug:
       var: container_processes.stdout_lines
```
Efektem dziaÅ‚ania mojego pipeline'a byÅ‚ plik binarny.

Na poczÄ…tku chciaÅ‚em pokazaÄ‡ dziaÅ‚anie irssi przez uÅ¼ycie zwykÅ‚ej komendy ps, ale obraz fedory w kontenerze domyÅ›lnie tego polecenia nie zawiera, dlatego naleÅ¼aÅ‚o wyÅ›wietliÄ‡ zawartoÅ›Ä‡ folderu /proc ktÃ³ry zawiera linki do aktualnie dziaÅ‚ajÄ…cych procesÃ³w.

Efekt dziaÅ‚ania powyÅ¼szego playbooka:

  ![Uruchomiony Playbook](Images/playbook2.png "Efekt uruchomienia Playbooka2")

Ubierz powyÅ¼sze kroki w [*rolÄ™*](https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_reuse_roles.html), za pomocÄ… szkieletowania `ansible-galaxy`

PoniÅ¼ej sÄ… polecenia ktÃ³re wykonaÅ‚em w celu stworzenia i skonfigurowania roli ( do plikÃ³w main.yml dodawaÅ‚em odpowiednie czÄ™Å›ci powyÅ¼szego pliku playbooka odpowiednio : w folderze defaults: zmienne vars. W folderze tasks: zadania okreÅ›lone w sekcji tasks. plik binarny irssi skopiowwaÅ‚em do folderu 'files' )

  ![Tworzenie roli](Images/role_creation.png "Tworzenie roli")

  PoniÅ¼ej znajduje siÄ™ treÅ›Ä‡ trzeciego playbooka ktÃ³ry korzysta ze stworzonej powyÅ¼ej roli:

  ```
- hosts: Endpoints
  roles:
    - irssiDep
  ```

  Jest on bardzo ktÃ³tki poniewaÅ¼ praktycznie caÅ‚Ä… treÅ›Ä‡ przenieÅ›liÅ›my do roli.

  PoniÅ¼ej znajduje siÄ™ efekt wywoÅ‚ania playbooka korzystajÄ…cego z roli :

  ![Komunikaty wyjÅ›ciowe dziaÅ‚ania playbooka](Images/role_playbook_out.png "Komunikaty wyjÅ›ciowe dziaÅ‚ania playbooka")

## Laboratorium 9 - Pliki odpowiedzi dla wdroÅ¼eÅ„ nienadzorowanych

### Zagadnienie
Niniejszy temat jest poÅ›wiÄ™cony przygotowaniu ÅºrÃ³dÅ‚a instalacyjnego systemu dla maszyny wirtualnej/fizycznego serwera/Å›rodowiska IoT. Å¹rÃ³dÅ‚a takie stosowane sÄ… do zautomatyzowania instalacji Å›rodowiska testowego dla oprogramowania, ktÃ³re nie pracuje w caÅ‚oÅ›ci w kontenerze

### Cel zadania
* UtworzyÄ‡ ÅºrÃ³dÅ‚o instalacji nienadzorowanej dla systemu operacyjnego hostujÄ…cego nasze oprogramowanie
* PrzeprowadziÄ‡ instalacjÄ™ systemu, ktÃ³ry po uruchomieniu rozpocznie hostowanie naszego programu

## Zadania do wykonania

ğŸŒµ PrzeprowadÅº instalacjÄ™ nienadzorowanÄ… systemu Fedora z pliku odpowiedzi z naszego repozytorium

* Zainstaluj [system Fedora](https://download.fedoraproject.org/pub/fedora/linux/releases/)
  * zastosuj instalator sieciowy (*Server Netinst*) lub
  * zastosuj instalator wariantu *Everything* z wbudowanymi pakietami, przyjmujÄ…cy plik odpowiedzi (dobra opcja dla osÃ³b z ograniczeniami transferu internetowego)
* Pobierz plik odpowiedzi `/root/anaconda-ks.cfg`

  skopiowaÅ‚em ze Å›cieÅ¼ki /root/anaconda-ks.cfg plik odpowiedzi do naszego repozytorium, Å›cieÅ¼ka: https://raw.githubusercontent.com/InzynieriaOprogramowaniaAGH/MDO2025_INO/refs/heads/JK403999/ITE/GCL04/JK403999/Sprawozdanie3/anaconda-ks.cfg

* Plik odpowiedzi moÅ¼e nie zawieraÄ‡ wzmianek na temat potrzebnych repozytoriÃ³w. Na przykÅ‚ad, dla systemu Fedora 38:
  * `url --mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=fedora-38&arch=x86_64`
  * `repo --name=update --mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=updates-released-f38&arch=x86_64`
* Plik odpowiedzi moÅ¼e zakÅ‚adaÄ‡ pusty dysk. Zapewnij, Å¼e zawsze bÄ™dzie formatowaÄ‡ caÅ‚oÅ›Ä‡, stosujÄ…c `clearpart --all`

  Ja z kolei spotkaÅ‚em siÄ™ z innym bÅ‚Ä™dem, a mianowicie przy tworzeniu maszyny w virtual boxie, przydzieliÅ‚em jej mniej dysku niÅ¼ tej oryginalnej, i przez to instalator prÃ³bowaÅ‚ przydzieliÄ‡ 30 GB, podczas gdy 
  dostÄ™pne byÅ‚o tylko 10 GB. Wszystko byÅ‚oby w porzÄ…dku gdyby nie to Å¼e komunikat instalatora brzmiaÅ‚: "NiewystarczajÄ…cy plik odpowiedzi".
  Gdy juÅ¼ zrozumiaÅ‚em jaki jest bÅ‚Ä…d, to naleÅ¼aÅ‚o tylko stworzyÄ‡ od nowa maszynÄ™ i przydzieliÄ‡ przynajmniej tyle miejsca ile oryginalnej maszynie( albo zmniejszyÄ‡ rÄ™cznie iloÅ›Ä‡ potrzebnych danych w pliku odpowiedzi )

* Ustaw *hostname* inny niÅ¼ domyÅ›lny `localhost`

  Komenda do podania pliku odpowiedzi podczas instalacji to w moim przypadku (moÅ¼na uÅ¼yÄ‡ teÅ¼ skracacza linkÃ³w) :
   ```
   inst.ks=https://raw.githubusercontent.com/InzynieriaOprogramowaniaAGH/MDO2025_INO/refs/heads/JK403999/ITE/GCL04/JK403999/Sprawozdanie3/anaconda-ks.cfg
   ```

* Rozszerz plik odpowiedzi o repozytoria i oprogramowanie potrzebne do uruchomienia programu, zbudowanego w ramach projektu - naszego *pipeline'u*. 
  * W przypadku kontenera, jest to po prostu Docker.
    * UtwÃ³rz w sekcji `%post` mechanizm umoÅ¼liwiajÄ…cy pobranie i uruchomienie kontenera
    * JeÅ¼eli efektem pracy pipeline'u nie byÅ‚ kontener, a aplikacja samodzielna - zainstaluj jÄ…
    * PamiÄ™taj, Å¼e **Docker zadziaÅ‚a dopiero na uruchomionym systemie!** - nie da siÄ™ wdaÄ‡ w interakcjÄ™ z Dockerem z poziomu instalatora systemu: polecenia `docker run` nie powiodÄ… siÄ™ na tym etapie. Nie zadziaÅ‚a teÅ¼ `systemctl start` (ale `systemctl enable` juÅ¼ tak)
  * Gdy program pracuje poza kontenerem, potrzebny jest caÅ‚y Å‚aÅ„cuch dependencji oraz sam program.
    * UÅ¼yj sekcji `%post`, by pobraÄ‡ z Jenkinsa zbudowany artefakt

        MÃ³j url do pobrania z jenkinsa: http://192.168.56.1:8080/job/SCM_Pipeline/lastSuccessfulBuild/artifact/irssi/irssi

    * RozwaÅ¼ stworzenie repozytorium ze swoim programem i dodanie go dyrektywÄ… `repo` oraz zainstalowanie pakietu sekcjÄ… `%packages`
    * JeÅ¼eli nie jest to moÅ¼liwe/wykonalne, uÅ¼yj dowolnego serwera SFTP/FTP/HTTP aby "zahostowaÄ‡" program - nastÄ™pnie pobierz go z tak hostujÄ…cego serwera (stosujÄ…c np. `wget`)
    * UmieÅ›Ä‡ program w Å›cieÅ¼ce stosownej dla binariÃ³w `/usr/local/bin/`
    * Zadbaj w sekcji `%packages`, by system zainstalowaÅ‚ wszystkie dependencje potrzebne do dziaÅ‚ania programu
  * Wybierz oprogramowanie na podstawie poprzedniego sprawozdania.
  * Zapoznaj siÄ™ z [dokumentacjÄ… pliku odpowiedzi](https://pykickstart.readthedocs.io/en/latest/kickstart-docs.html)
  * UÅ¼yj pliku odpowiedzi do przeprowadzenia [instalacji nienadzorowanej](https://docs.fedoraproject.org/en-US/fedora/f36/install-guide/advanced/Kickstart_Installations/)
* Zadbaj o automatyczne ponowne uruchomienie na koÅ„cu instalacji
* Zapewnij, by od razu po pierwszym uruchomieniu systemu, oprogramowanie zostaÅ‚o uruchomione (w dowolny sposÃ³b)

  Ostateczny plik anaconda-ks.cfg:
```
# Generated by Anaconda 41.35
# Generated by pykickstart v3.58
#version=DEVEL

# Keyboard layouts
keyboard --vckeymap=pl --xlayouts='pl'
# System language
lang pl_PL.UTF-8

# Network information
network  --bootproto=dhcp --device=enp0s3 --ipv6=auto --activate
network  --hostname=jakkorz

%packages
@^server-product-environment
glib2
openssl-libs
ncurses
perl

%end

%post
wget --user=root --password=aaaa \
http://192.168.56.1:8080/job/SCM_Pipeline/lastSuccessfulBuild/artifact/irssi/irssi -O irssi
mv irssi /usr/local/bin/irssi

cat <<EOF > /etc/systemd/system/irssi.service
[Unit]
Description=Irssi autostart service
After=network.target

[Service]
ExecStart=/usr/local/bin/irssi
Restart=always
User=root

[Install]
WantedBy=multi-user.target
EOF

systemctl enable irssi.service

echo "systemctl reboot" >> /etc/rc.d/rc.local
chmod +x /etc/rc.d/rc.local

%end

# Run the Setup Agent on first boot
firstboot --enable

# Generated using Blivet version 3.11.0
ignoredisk --only-use=sda
# Partition clearing information
clearpart --all --initlabel
# Disk partitioning information
part /boot --fstype="ext4" --ondisk=sda --size=1024
part pv.48 --fstype="lvmpv" --ondisk=sda --size=35837
part biosboot --fstype="biosboot" --ondisk=sda --size=1
volgroup fedora_jakkorz --pesize=4096 pv.48
logvol / --fstype="ext4" --grow --maxsize=71680 --size=1024 --name=root --vgname=fedora_jakkorz

# System timezone
timezone Europe/Warsaw --utc

# Root password
rootpw --iscrypted --allow-ssh $y$j9T$oGuE12lf4pzUttXSQZqrN3GB$RhftiA11WvLnHUGl5UkwPoLp50qFVsaxROzyDidWJr4
```

## Laboratorium 10 - WdraÅ¼anie na zarzÄ…dzalne kontenery: Kubernetes

### Instalacja klastra Kubernetes
 * ğŸŒµ Zaopatrz siÄ™ w implementacjÄ™ stosu k8s: [minikube](https://minikube.sigs.k8s.io/docs/start/)
 * PrzeprowadÅº instalacjÄ™, wykaÅ¼ poziom bezpieczeÅ„stwa instalacji
 * Zaopatrz siÄ™ w polecenie `kubectl` w wariancie minikube, moÅ¼e byÄ‡ alias `minikubctl`, jeÅ¼eli masz juÅ¼ "prawdziwy" `kubectl`
 * Uruchom Kubernetes, pokaÅ¼ dziaÅ‚ajÄ…cy kontener/worker
 * Zmityguj problemy wynikajÄ…ce z wymagaÅ„ sprzÄ™towych lub odnieÅ› siÄ™ do nich (wzglÄ™dem dokumentacji)
 * ğŸŒµ Uruchom Dashboard, otwÃ³rz w przeglÄ…darce, przedstaw Å‚Ä…cznoÅ›Ä‡

      ![Uruchomiony dashboard Kubernetes](Images/dashboard.png "Uruchomiony dashboard Kubernetes")

 * Zapoznaj siÄ™ z koncepcjami funkcji wyprowadzanych przez Kubernetesa (*pod*, *deployment* itp)
 
### Analiza posiadanego kontenera
 * Zdefiniuj krok "Deploy" swojego projektu jako "Deploy to cloud":
   * Deploy zbudowanej aplikacji powinien siÄ™ odbywaÄ‡ "na kontener"
   * Przygotuj obraz Docker ze swojÄ… aplikacjÄ… - sprawdÅº, Å¼e TwÃ³j kontener Deploy na pewno **pracuje**, a nie natychmiast koÅ„czy pracÄ™! ğŸ˜
   * JeÅ¼eli wybrana aplikacja nie nadaje siÄ™ do pracy w kontenerze i nie wyprowadza interfejsu funkcjonalnego przez sieÄ‡, wymieÅ„ projekt na potrzeby tego zadania:
     * Optimum:
       * obraz-gotowiec (czyli po prostu inna aplikacja, np. `nginx`, ale **z dorzuconÄ… wÅ‚asnÄ… konfiguracjÄ…**)
       * samodzielnie wybrany program i obraz zbudowany na jego bazie, niekoniecznie via *pipeline*
     * Plan max: obraz wygenerowany wskutek pracy *pipeline'u*
   * WykaÅ¼, Å¼e wybrana aplikacja pracuje jako kontener

       ![Uruchomiony kontener nginx](Images/working_nginx.png "Uruchomiony kontener nginx")  

       I poniÅ¼ej wynik dostÄ™pu do nginx z przeglÄ…darki

       ![Nginx w przeglÄ…darce](Images/nginx_browser.png "Nginx w przeglÄ…darce")
   
### Uruchamianie oprogramowania
 * ğŸŒµ Uruchom kontener ze swojÄ…/wybranÄ… aplikacjÄ… na stosie k8s
 * Kontener uruchomiony w minikubie zostanie automatycznie "ubrany" w *pod*.

 * ```minikube kubectl run -- <nazwa-jednopodowego-wdroÅ¼enia> --image=<obraz-docker> --port=<wyprowadzany port> --labels app=<nazwa-jednopodowego-wdroÅ¼enia>```

![Stworzenie poda](Images/pod_created.png "Stworzenie poda")  

 * Przedstaw Å¼e *pod* dziaÅ‚a (via Dashboard oraz `kubectl`)

![DziaÅ‚ajÄ…cy pod wyÅ›wietlony w dashboardzie](Images/working_pod.png "DziaÅ‚ajÄ…cy pod wyÅ›wietlony w dashboardzie")  

![DziaÅ‚ajÄ…cy pod wyÅ›wietlony w terminalu przez polecenie kubectl](Images/working_pod_terminal.png "DziaÅ‚ajÄ…cy pod wyÅ›wietlony w terminalu przez polecenie kubectl")  


 * WyprowadÅº port celem dotarcia do eksponowanej funkcjonalnoÅ›ci
 * ```kubectl port-forward pod/<nazwa-wdroÅ¼enia> <LO_PORT>:<PODMAIN_CNTNR_PORT> ```

        MiaÅ‚em problem aby kubernetes rzeczywiÅ›cie korzystaÅ‚ ze stworzonego nginxowego obrazu zamiast z tego domyÅ›lnego z docker-hub.
        Ostatecznie zastosowaÅ‚em nastÄ™pujÄ…ce rozwiÄ…zanie: https://stackoverflow.com/questions/42564058/how-can-i-use-local-docker-images-with-minikube#42564211, 
        czyli:
        eval $(minikube docker-env)
        I dziÄ™ki temu mogÅ‚em zbudowaÄ‡ obraz na daemonie minikuba.
        PÃ³Åºniej juÅ¼ tylko wystarczy pamiÄ™taÄ‡ Å¼eby ustawiÄ‡ ```imagePullPolicy=Never``` Å¼eby minikube nie pobieraÅ‚ z repozytorium.
        Ostatecznie polecenie kubectl run miaÅ‚o postaÄ‡:
        ```minikube kubectl -- run nginx   --image=jknginx:latest   --port=80   --labels app=nginxKubDep --image-pull-policy=Never```

![Port forwarding](Images/port_forward.png "Port forwarding")  

 * Przedstaw komunikacjÄ™ z eskponowanÄ… funkcjonalnoÅ›ciÄ…

![Nginx za pomoca kubernetesa](Images/nginx_kubernetes.png "Nginx za pomoca kubernetesa")  
 
### Przekucie wdroÅ¼enia manualnego w plik wdroÅ¼enia (wprowadzenie)
 * Zapisz [wdroÅ¼enie](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) jako plik YML

Plik wdroÅ¼enia prezentuje siÄ™ nastÄ™pujÄ…co:

  ```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
  ```

 * PrzeprowadÅº prÃ³bne wdroÅ¼enie przykÅ‚adowego *deploymentu* (moÅ¼e byÄ‡ `nginx`)
   * Wykonaj ```kubectl apply``` na pliku

![Uruchomienie deploymentu](Images/deployment.png "Uruchomienie deploymentu") 

   * Upewnij siÄ™, Å¼e posiadasz wdroÅ¼enie zapisane jako plik
   * WzbogaÄ‡ swÃ³j *deployment* o 4 repliki
   * Rozpocznij wdroÅ¼enie za pomocÄ… ```kubectl apply```

![Uruchomienie deploymentu](Images/deployment.png "Uruchomienie deploymentu") 

   * Zbadaj stan za pomocÄ… ```kubectl rollout status```

![Sprawdzenie statusu deploymentu](Images/status.png "Sprawdzenie statusu deploymentu") 

 * Wyeksponuj wdroÅ¼enie jako serwis
 * Przekieruj port do serwisu (tak, jak powyÅ¼ej)

## ZajÄ™cia 11 - WdraÅ¼anie na zarzÄ…dzalne kontenery: Kubernetes (2)

### Przygotowanie nowego obrazu
 * Zarejestruj nowÄ… wersjÄ™ swojego obrazu `Deploy` (w Docker Hub lub lokalnie+przeniesienie)

![Dodatkowe obrazy dodane do dockerhuba](Images/docker_hub.png "Dodatkowe obrazy dodane do dockerhuba") 
 
 * Upewnij siÄ™, Å¼e dostÄ™pne sÄ… dwie co najmniej wersje obrazu z wybranym programem
 * JeÅ¼eli potrzebny jest "gotowiec" z powodu problemÃ³w z `Deploy`, moÅ¼na uÅ¼yÄ‡ np `httpd`, ale powinien to byÄ‡ **wÅ‚asny** kontener: zmodyfikowany wzglÄ™dem oryginaÅ‚u i opublikowany na wÅ‚asnym koncie Docker Hub.
 * BÄ™dzie to wymagaÄ‡ 
   * przejÅ›cia przez *pipeline* dwukrotnie, lub
   * rÄ™cznego zbudowania dwÃ³ch wersji, lub
   * przepakowania wybranego obrazu samodzielnie np przez ```commit```
 * Przygotuj kolejnÄ… wersjÄ™ obrazu, ktÃ³rego uruchomienie koÅ„czy siÄ™ bÅ‚Ä™dem

 Aby uruchomienie kontenera koÅ„czyÅ‚o siÄ™ bÅ‚Ä™dem dodaÅ‚em nastÄ™pujÄ…cÄ… linijkÄ™ na koniec pliku Dockerfile:

 ``` CMD sh -c "echo 'Starting jknginx...' && exec nginxabcd -g 'daemon off;'" ``` - Powinno wypisaÄ‡ Å¼e nie moÅ¼e uruchomiÄ‡ nginxabcd.
  
### Zmiany w deploymencie
 * ğŸŒµ Aktualizuj plik YAML z wdroÅ¼eniem i przeprowadzaj je ponownie po zastosowaniu nastÄ™pujÄ…cych zmian:
   * zwiÄ™kszenie replik np. do 8

![DziaÅ‚ajÄ…ce 8 replik](Images/8pods.png "DziaÅ‚ajÄ…ce 8 replik") 

   * zmniejszenie liczby replik do 1

![DziaÅ‚ajÄ…ca 1 replika](Images/1pod.png "DziaÅ‚ajÄ…ca 1 replika") 

   * zmniejszenie liczby replik do 0

![0 replik](Images/0pods.png "0 replik") 

   * ponowne przeskalowanie w gÃ³rÄ™ do 4 replik (co najmniej)
   * Zastosowanie nowej wersji obrazu

![Nowa wersja obrazu](Images/pod_new.png "Nowa wersja obrazu") 

   * Zastosowanie starszej wersji obrazu
   * Zastosowanie "wadliwego" obrazu

![Wersja obrazu zwracajÄ…ca bÅ‚Ä…d](Images/err_pods.png "Wersja obrazu zwracajÄ…ca bÅ‚Ä…d") 

 * Przywracaj poprzednie wersje wdroÅ¼eÅ„ za pomocÄ… poleceÅ„
   * ```kubectl rollout history```
   * ```kubectl rollout undo```

### Kontrola wdroÅ¼enia
 * Zidentyfikuj historiÄ™ wdroÅ¼enia i zapisane w niej problemy, skoreluj je z wykonywanymi czynnoÅ›ciami

![Nowa wersja obrazu](Images/rollout_history.png "Nowa wersja obrazu") 

![Nowa wersja obrazu](Images/describe.png "Nowa wersja obrazu") 
 
 